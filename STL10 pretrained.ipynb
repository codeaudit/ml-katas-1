{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> The STL-10 dataset is an image recognition dataset for developing unsupervised feature learning, deep learning, self-taught learning algorithms. It is inspired by the CIFAR-10 dataset but with some modifications. In particular, each class has fewer labeled training examples than in CIFAR-10, but a very large set of unlabeled examples is provided to learn image models prior to supervised training. The primary challenge is to make use of the unlabeled data (which comes from a similar but different distribution from the labeled data) to build a useful prior. We also expect that the higher resolution of this dataset (96x96) will make it a challenging benchmark for developing more scalable unsupervised learning methods.\n",
    "\n",
    "\n",
    "The STL-10 dataset is interesting as it basically provides you two ways of solving it: \n",
    "- Use a pretrained network\n",
    "- Learn the image features, for example using a autoencoder to learn what features are important\n",
    "\n",
    "In this notebook I will provide a basic example of using a pretrained network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils.plot_utils \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data/stl10_binary.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform=torchvision.transforms.Compose([\n",
    "                           torchvision.transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_dataset = torchvision.datasets.STL10('./data', split='train', transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.STL10('./data', split='test', transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_every=300):\n",
    "    model.train()\n",
    "    losses = list()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_every == 0:\n",
    "            losses.append(loss.item())\n",
    "    return losses\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.mse_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "def get_pretrained_network():\n",
    "    resnet = models.resnet18(pretrained=True)\n",
    "    modules = list(resnet.children())[:-1] # delete the last fc layer and spatial pooling layer\n",
    "    # We use a smaller image size, so replace the avg pool \n",
    "    modules[-1] = torch.nn.AvgPool2d(kernel_size=3, stride=1, padding=0) \n",
    "    resnet = nn.Sequential(*modules)\n",
    "    ### Now set requires_grad to false\n",
    "    for param in resnet.parameters():\n",
    "        param.requires_grad = False\n",
    "    return resnet\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.pretrained = get_pretrained_network()\n",
    "        self.fc = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pretrained(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return F.softmax(x, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a090860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.FloatTensor but found type torch.LongTensor for argument #2 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a98e000e6d0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-44f068cd82ab>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sum up batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get the index of the max log-probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pointwise_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pointwise_loss\u001b[0;34m(lambd, lambd_optimized, input, target, reduction)\u001b[0m\n\u001b[1;32m   1672\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'elementwise_mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlambd_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.FloatTensor but found type torch.LongTensor for argument #2 'target'"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=64\n",
    "TEST_BATCH_SIZE=64\n",
    "EPOCHS=10\n",
    "LEARNING_RATE=0.01\n",
    "\n",
    "model = Network().to(device)\n",
    "optimizer = optim.Adam(model.parameters()) # Feel free to use a different optimizer\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = train(model, device, train_loader, optimizer, epoch)\n",
    "    utils.plot_utils.plot_loss(losses, epoch)\n",
    "    test(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = resnet18(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18.fc.out_features = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = resnet(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 1, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
